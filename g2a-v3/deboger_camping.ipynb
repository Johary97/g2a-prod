{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import ElementNotVisibleException, ElementNotSelectableException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from unidecode import unidecode\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from datetime import datetime, timedelta\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.campings.com/fr/camping/camping-les-salisses-76793#?checkInDate=2024-04-20&night=7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_scrap = \"18/03/2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['camping-les-salisses-76793#', 'checkInDate=2024-04-20&night=7']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.current_url.replace(\"https://www.campings.com/fr/camping/\", '').split('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_data() -> tuple:\n",
    "    \"\"\" function to get dates in url \"\"\"\n",
    "    url = driver.current_url\n",
    "    data = url.replace(\"https://www.campings.com/fr/camping/\", '').split('?')\n",
    "    station_key = data[0][:-1]\n",
    "\n",
    "    try:\n",
    "        checkin_date = (datetime.strptime(data[1][23:33].replace('-', '/'), \"%Y/%m/%d\")).strftime(\"%d/%m/%Y\")\n",
    "    except:\n",
    "        checkin_date = (datetime.strptime(data[1][12:22].replace('-', '/'), \"%Y/%m/%d\")).strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    checkout_date = (datetime.strptime(checkin_date, \"%d/%m/%Y\") + timedelta(days=7)).strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "    return station_key, checkin_date, checkout_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('camping-les-salisses-76793', '20/04/2024', '27/04/2024')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_link_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "soupe = BeautifulSoup(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soupe.find('div', {'class':'results__list'}).find_all('div', {'class':'accommodation-card result__card'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = results[0].find('div', {'class':'accommodation-card__offer-dates'}).text.strip().split(',')[0].replace('Du ', '').replace('au ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dates(string_date,year):\n",
    "    months = {'janv.': 1, 'févr.': 2, 'mars': 3, 'avr.': 4, 'mai': 5, 'juin': 6, 'juil.': 7, 'août': 8, 'sept.': 9, 'oct.': 10, 'nov.': 11, 'déc.': 12}\n",
    "    split_date = string_date.split(' ')\n",
    "    start_date = f\"{split_date[0]}/{months[split_date[-1]]}/{year}\"\n",
    "    end_date = f\"{split_date[1]}/{months[split_date[-1]]}/{year}\"\n",
    "    return start_date, end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('20/4/2024', '27/4/2024')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_dates(date, 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "def extract() -> None:\n",
    "    def extract_dates(string_date,year):\n",
    "        months = {'janv.': '01', 'févr.': '02', 'mars': '03', 'avr.': '04', 'mai': '05', 'juin': '06', 'juil.': '07', 'août': '08', 'sept.': '09', 'oct.': '10', 'nov.': '11', 'déc.': '12'}\n",
    "        split_date = string_date.split(' ')\n",
    "        start_date = f\"{split_date[0]}/{months[split_date[-1]]}/{year}\"\n",
    "        end_date = f\"{split_date[1]}/{months[split_date[-1]]}/{year}\"\n",
    "        return start_date, end_date\n",
    "\n",
    "    try:\n",
    "        soupe = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        name = ''.join(soupe.find('h1', {'class':'product__name'}).text.strip().split('\\n')[:-1]) \\\n",
    "            if soupe.find('h1', class_='product__name') else ''\n",
    "        localite = ''\n",
    "\n",
    "        try:\n",
    "            localite = ''.join(soupe.find('div', class_='product__localisation').text.strip().split('\\n')[0].split('-')[1]).replace(\", FRANCE\", \"\") \\\n",
    "                if soupe.find('div', class_='product__localisation') else ''\n",
    "        except IndexError:\n",
    "            localite = soupe.find('div', class_='product__localisation').text.strip().replace(\"- Voir sur la carte\", \"\") \\\n",
    "                if soupe.find('div', class_='product__localisation') else ''\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "        try:\n",
    "            results = soupe.find('div', {'class':'results__list'}).find_all('div', {'class':'accommodation-card result__card'}) \\\n",
    "                if soupe.find('div', {'class':'results__list'}) else []\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        datas = []\n",
    "        station_key, date_debut, date_fin = get_link_data()\n",
    "        final_results = []\n",
    "\n",
    "        for result in results:\n",
    "            dates_string = result.find('div', {'class':'accommodation-card__offer-dates'}).text.strip().split(',')[0].replace('Du ', '').replace('au ', '')\n",
    "            date_start, date_end = extract_dates(dates_string, year=date_debut.split('/')[2])\n",
    "            if date_start == date_debut:\n",
    "                final_results.append(result)\n",
    "\n",
    "        for result in final_results:\n",
    "            data = {}\n",
    "            typologie = result.find('div', {'class':'accommodation-card__name'}).text.strip() \\\n",
    "                if result.find('div', {'class':'accommodation-card__name'}) else ''\n",
    "            adulte = result.find('div', {'data-property':'adults'}).text.strip() \\\n",
    "                if result.find('div', {'data-property':'adults'}) else ''\n",
    "            prix_actuel = result.find('div', {'class':'accommodation-card__offer-price'}).text.strip().replace('€', '').replace('\\xa0', '').replace(',', '.') \\\n",
    "                if result.find('div', {'class':'accommodation-card__offer-price'}) else ''\n",
    "            prix_init = result.find('div', {'class':'accommodation-card__offer-old-price'}).find('span').text.strip().replace('€', '').replace('\\xa0', '').replace(',', '.') \\\n",
    "                if result.find('div', {'class':'accommodation-card__offer-old-price'}) else prix_actuel\n",
    "\n",
    "            data['web-scrapper-order'] = ''\n",
    "            data['date_price'] = week_scrap\n",
    "            data['date_debut'] = date_debut\n",
    "            data['date_fin'] = date_fin\n",
    "            data['prix_init'] = prix_init\n",
    "            data['prix_actuel'] = prix_actuel\n",
    "            data['typologie'] = typologie.replace('\\n', ' ')\n",
    "            data['nom'] = name.replace('\\n', ' ')\n",
    "            data['Nb personnes'] = adulte.replace('\\n', ' ')\n",
    "            data['localite'] = localite.replace('\\n', ' ')\n",
    "            data['n_offre'] = ''\n",
    "            data['date_debut-jour'] = ''\n",
    "            data['Nb semaines'] = datetime.strptime(date_debut, '%d/%m/%Y').isocalendar()[1]\n",
    "            data['cle_station'] = station_key\n",
    "            data['nom_station'] = ''\n",
    "            data['url'] = driver.current_url.split('?')[-1]\n",
    "            print(data)\n",
    "            datas.append(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        driver.quit()\n",
    "        raise Exception(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
